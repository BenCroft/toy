{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REGRESSION MODELING\n",
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective:\n",
    "In this analysis project, our goal is to apply statistical modeling in the form of regression to data related to student success. \n",
    "\n",
    "### What does \"supervised machine learning\" mean?\n",
    "- Machine learning, in a broad sense, is an approach to data analytics that allows computers to learn from data without being explicitly told so. From driverless cars to artificial intelligence, machine learning has countless applications, but here we will use machine learning to train the computer to identify hidden relationships in data and apply what it learned to future data.\n",
    "\n",
    "\n",
    "### What is regression?\n",
    "Regression is a statistical modeling approach that seeks to determine and evaluate the strength of the relationship between an dependent variable (y) and one or more independent variables (x1, x2, x3, ...).\n",
    "\n",
    "\n",
    "### What types of regression are there?\n",
    "There are several types of regression models (logistic, general linear models, additive models, etc.), and even more variations and levels of those models. In this project, we will use the linear regression, the most commonly used approach to modeling and data analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******\n",
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install and load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependency ‘isoband’\n",
      "\n",
      "Warning message in install.packages(\"ggplot2\", verbose = FALSE):\n",
      "“installation of package ‘isoband’ had non-zero exit status”Warning message in install.packages(\"ggplot2\", verbose = FALSE):\n",
      "“installation of package ‘ggplot2’ had non-zero exit status”Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n",
      "also installing the dependencies ‘xfun’, ‘pkgbuild’, ‘diffobj’, ‘rematch2’, ‘isoband’, ‘callr’, ‘fs’, ‘knitr’, ‘brio’, ‘cli’, ‘pkgload’, ‘processx’, ‘ps’, ‘rlang’, ‘waldo’, ‘ggplot2’, ‘reprex’, ‘feather’, ‘testthat’\n",
      "\n"
     ]
    }
   ],
   "source": [
    "install.packages(\"ggplot2\", verbose = FALSE)\n",
    "install.packages(\"vtreat\", verbose = FALSE)\n",
    "install.packages(\"tidyverse\", verbose = FALSE, dependencies = TRUE)\n",
    "\n",
    "library(ggplot2)\n",
    "library(vtreat)\n",
    "library(tidyverse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the hypothetical data\n",
    "\n",
    "*Disclaimer: 1) This step is to generate simulated data that we can work with in our modeling process. Clearly, the measures of central tendency, the measures of dispersion, and the betas associated with variables in the models are not reflective of reality. 2) The actual linear regression models fitted (and k-fold cross validated) here are very cursory. True models would include more variables. The goal of this notebook is to demonstrate the modeling process - *not* models themselves.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(expr, envir, enclos): object 'midtermGrade' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(expr, envir, enclos): object 'midtermGrade' not found\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Set the seed for RNG reproducibility\n",
    "set.seed(10)\n",
    "\n",
    "# CREATE TRAINING SET (this is a dataset containing fictitious student data)\n",
    "id <- 1:150\n",
    "onlineBefore <- sample(c(TRUE,FALSE), 150, replace = TRUE, prob = c(0.6,0.4))\n",
    "GPA <- round(rnorm(150, 3.0, .4), digits=1)\n",
    "finalGrade <- 0.93*midtermGrade + 5*onlineBefore + sample(rnorm(1, 0, 20), 150, replace = TRUE)\n",
    "\n",
    "# CREATE TEST SET\n",
    "id2 <- 1:50\n",
    "onlineBefore2 <- sample(c(TRUE,FALSE), 50, replace = TRUE, prob = c(0.6,0.4))\n",
    "GPA2 <- round(rnorm(150, 2.9, .4), digits=1)\n",
    "\n",
    "# DATA FRAMES\n",
    "StudentsDF.train <- data.frame(id, onlineBefore, GPA, finalGrade)\n",
    "StudentsDF.test <- data.frame(id2, onlineBefore2, GPA)\n",
    "\n",
    "# PREVIEW THE FIRST 4 ROWS OF THE TRAINING SET AND THE TEST SET\n",
    "head(StudentsDF.train, 4)\n",
    "head(StudentsDF.test, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train a linear regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But wait - was does \"training a linear regression model mean?\"\n",
    "\n",
    "Our goal is to develop a statistical model (or equation) that tells us the relationship between the dependent variable/outcome (the final grade) and the dependent variables (the GPA of the student, whether the student has taken an online course before).\n",
    "\n",
    "\"Training\" refers to the process of creating a model that explains this relationship using a subset of the total data. Our algorithm will fit a line/curve to the 150 observations (students) in this dataset, something that would take quite a long time to do by hand. After training the model, we will apply it to data where we don't know the final grade. Our ultimate goal is to predict final grades of new data using the model trained on old data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in is.data.frame(data): object 'StudentsDF.train' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in is.data.frame(data): object 'StudentsDF.train' not found\nTraceback:\n",
      "1. lm(finalGrade ~ GPA + onlineBefore, data = StudentsDF.train)",
      "2. eval(mf, parent.frame())",
      "3. eval(mf, parent.frame())",
      "4. stats::model.frame(formula = finalGrade ~ GPA + onlineBefore, \n .     data = StudentsDF.train, drop.unused.levels = TRUE)",
      "5. model.frame.default(formula = finalGrade ~ GPA + onlineBefore, \n .     data = StudentsDF.train, drop.unused.levels = TRUE)",
      "6. is.data.frame(data)"
     ]
    }
   ],
   "source": [
    "# TRAIN THE MODEL\n",
    "\n",
    "model1 <- lm(finalGrade ~ GPA + onlineBefore, data = StudentsDF.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in summary(model1): object 'model1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in summary(model1): object 'model1' not found\nTraceback:\n",
      "1. summary(model1)"
     ]
    }
   ],
   "source": [
    "# MODEL DIAGNOSTICS\n",
    "\n",
    "summary(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few model diagnostics we can look at here. Perhaps the easiest numbers to decipher is the `Pr(>|t|)` column of under `coefficients`. In essence, this column tells us the probability of the observing the values of the variable if we assumed there was no relationship among variables. Here, we can interpret each of our variables as \"statistically significant\" (though this should be already clear, since we manually built the dependent variable `finalGrade` out of the dependent variables in the fictitious dataset). \n",
    "\n",
    "We also can evaluate the `Multiple R-squared` and `Adjusted R-squared` values. These values represent different forms of what statisticians call the \"coefficient of determination.\" R-squared values are generally used to tell us the power of our model to explain the variability of the data. An R-squared close to 1.00 is a very strong model, and likewise R-squared values close to 0 have very little explanatory power. R-squared isn't an end-all be-all metric of a model's worth, but it is a quick way to evaluate a model's efficacy. Here, our `Adjusted R-squared` value is 0.6926, which means our model explains about 69% of the variability in the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model to predict future data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a model that explains the relationship of `GPA` and `onlineBefore` on `finalGrade`. Great! We have found a pattern in the data! However, part of the power of linear regression is predicting the final grades of future students. In this section, we will apply our model to new data (the test set), where we aren't given the *actual* final grades (turning inputs into output)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in terms(object): object 'model1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in terms(object): object 'model1' not found\nTraceback:\n",
      "1. predict.lm(model1, data = StudentsDF.test)",
      "2. terms(object)"
     ]
    }
   ],
   "source": [
    "# Apply the learned model to the testing data, storing the predictions in a new column\n",
    "StudentsDF.test$predictions <- predict.lm(model1, data = StudentsDF.test)\n",
    "\n",
    "# Show the first few rows of the data fram with the new predictions column\n",
    "head(StudentsDF.test,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table above represents the dataframe of our test data, now with a `predictions` column. This column is our model's best guess as to what the final grades of students will be, given their `onlineBefore` status and `GPA`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in ggplot(StudentsDF.test, aes(x = predictions, y = finalGrade, : could not find function \"ggplot\"\n",
     "output_type": "error",
     "traceback": [
      "Error in ggplot(StudentsDF.test, aes(x = predictions, y = finalGrade, : could not find function \"ggplot\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "ggplot(StudentsDF.test, aes(x=predictions, y=finalGrade, color = onlineBefore)) +\n",
    "    geom_point() +\n",
    "    geom_abline(color = \"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpret the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in head(StudentsDF.test, 6): object 'StudentsDF.test' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in head(StudentsDF.test, 6): object 'StudentsDF.test' not found\nTraceback:\n",
      "1. head(StudentsDF.test, 6)"
     ]
    }
   ],
   "source": [
    "# Show the first few rows of the data frame\n",
    "head(StudentsDF.test, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goodness-of-fit metric we can use is R^2. This is equal to:\n",
    "1 - (variance of model)/(total variance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in broom::glance(model1): object 'model1' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in broom::glance(model1): object 'model1' not found\nTraceback:\n",
      "1. broom::glance(model1)"
     ]
    }
   ],
   "source": [
    "# Use tidyverse to pull the model diagnostics\n",
    "broom::glance(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a high r-squared value, we determine that our model is a strong fit to our data. 69% of the variation in the observed training data can be explained using our model. \n",
    "\n",
    "*Note: Again, this model is hypothetical, and doesn't reflect real-world values. By incorporating a larger quantity of data, as well as more predictors, we could tune our model to its best performance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************************************\n",
    "\n",
    "\n",
    "# EVALUATING THE PERFORMANCE OF OUR MODEL ON TRAINING AND TESTING DATA\n",
    "\n",
    "In the last section, we created a multivariate linear regression model using two sets of data: a dataset we trained our model on, and a new dataset with different values that predicted values for.\n",
    "\n",
    "In this section, we will use a similar modeling process. But this time, we do not have two separate datasets to work with. Moreover, we want to develop metrics to evaluate whether our model actually *can* be used to predict future values reliably (previously, we just assumed it could).\n",
    "\n",
    "To this end, we will partition our single dataset into a training subset and a testing subset using random assignment. Then we will train a model on the training set, apply it to the testing set, and see how well it predicted actual values of the testing set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set.seed(10)\n",
    "\n",
    "# Create some data\n",
    "id <- 1:150\n",
    "onlineBefore <- sample(c(TRUE,FALSE), 150, replace = TRUE, prob = c(0.6,0.4))\n",
    "GPA <- round(rnorm(150, 2.8, 0.3), digits=1)\n",
    "finalGrade <- 0.95*midtermGrade + 4*onlineBefore + sample(rnorm(1, 0, 10), 150, replace = TRUE)\n",
    "\n",
    "# Create the single dataframe and name it `Students`. Display the first few rows.\n",
    "Students <- data.frame(id, onlineBefore, GPA, finalGrade)\n",
    "head(Students, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the training and testing sets\n",
    "\n",
    "We will use 5-fold cross validation to segment our data into 5 subsets. We'll model the data 4 times with different subsets of the total data. This will allow us to test how well our total model will model new, future data.\n",
    "\n",
    "First, we'll partition the data into a training set (~75%) and a test set (~25%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows (observations) we have in the total set\n",
    "(N <- nrow(Students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the number of rows 75% of the total data should be\n",
    "(target <- round(0.75 * N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means we want to pull about 112 rows from our data set to train on. We pull these randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector of 112 random indices\n",
    "rowPull <- runif(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll use this vector of 112 random indices to create our training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "students_train <- Students[rowPull < 0.75,]\n",
    "students_test <- Students[rowPull >= 0.75,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model using our test and train split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a formula to express finalGrade as a function of midtermGrade and onlineBefore\n",
    "grade_formula <- finalGrade ~ GPA + onlineBefore\n",
    "\n",
    "# Create the linear model on the training data\n",
    "students_model <- lm(grade_formula, data = students_train)\n",
    "\n",
    "# Examine the model\n",
    "summary(students_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the learned model on the train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict finalGrade from the training set\n",
    "students_train$pred <- predict(students_model, students_train)\n",
    "\n",
    "# Predict finalGrade from the test set\n",
    "students_test$pred <- predict(students_model, students_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the performance of the model on both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to calculate RMSE and R^2\n",
    "# RMSE\n",
    "rmse <- function(actual, pred)\n",
    "{\n",
    "    sqrt(mean((actual - pred)^2))\n",
    "}\n",
    "\n",
    "# R-Squared\n",
    "R2  <- function(actual, pred)\n",
    "{\n",
    "    1 - (sum((actual-pred)^2)/sum((actual-mean(actual))^2))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's RMSE and R^2 on both sets\n",
    "print(\"RMSE for the model on the train and test sets are:\")\n",
    "(rmse_train <- rmse(students_train$finalGrade, students_train$pred))\n",
    "(rmse_test <- rmse(students_test$finalGrade, students_test$pred))\n",
    "\n",
    "print(\"R-Squared for the model on the train and test sets are:\")\n",
    "(R2_train <- R2(students_train$finalGrade, students_train$pred))\n",
    "(R2_test <- R2(students_test$finalGrade, students_test$pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the predicted grades vs. the final grades to see how well our model predicted\n",
    "ggplot(students_test, aes(x = pred, y = finalGrade)) + \n",
    "    geom_point() +\n",
    "    geom_abline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It looks like our model performs well on the test set!\n",
    "\n",
    "About 88.9% of the variation in the final grades observed is predicted by our model on its training data.\n",
    "\n",
    "About 90.6% of the variation in the final grades observed is predicted by our model on its test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-FOLD CROSS VALIDATION "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-fold validation predicts how a model created from all the data will perform on new data. \n",
    "\n",
    "We will perform 5-fold cross validation using the `kWayCrossValidtiation` function in the `vtreat` package. This speeds up the process quite significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain the number of rows in the dataset \n",
    "numRows <- nrow(Students)\n",
    "\n",
    "# Implement a 5-fold cross validation plan\n",
    "splitPlan <- kWayCrossValidation(numRows, 5, NULL, NULL)\n",
    "\n",
    "# Examine our split plan\n",
    "str(splitPlan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The split plan is a list of elements that contains two vectors:**\n",
    "1. `train`: this is the list of indices of `Students` that will form the training set\n",
    "2. `app`: this is the list of indices that form the test set (also called the application set) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using our split plan (aka cross validation plan), we will make predictions from a model\n",
    "\n",
    "# Set k = 5. This is the number of folds we'll use.\n",
    "k <- 5\n",
    "\n",
    "# Initialize a column of the appropriate length\n",
    "Students$pred.cv <- 0\n",
    "\n",
    "# Get the ith split\n",
    "# Build a model on the training data from this split\n",
    "# Make predictions on the test data from this split\n",
    "\n",
    "for (i in 1:k) {\n",
    "    split <- splitPlan[[i]]\n",
    "    model <- lm(finalGrade ~ GPA + onlineBefore, data = Students[split$train,])\n",
    "    Students$pred.cv[split$app] <- predict(model, newdata = Students[split$app,])            \n",
    "}\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using a full model (all the data, not subsetted in cross validation)\n",
    "Students$pred <- predict(lm(finalGrade ~ midtermGrade + onlineBefore, data = Students))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the RMSE of the cross-validation predictions and the full model predictions\n",
    "print(\"The RMSE of the CV predictions and full model predictions:\")\n",
    "rmse(Students$finalGrade, Students$pred.cv)\n",
    "rmse(Students$finalGrade, Students$pred)\n",
    "\n",
    "# Get the R-Squared of the cross-validation predictions and the full model predictions\n",
    "print(\"The R-Squared of the CV predictions and the full model predictions\")\n",
    "R2(Students$finalGrade, Students$pred.cv)\n",
    "R2(Students$finalGrade, Students$pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INTERPRET THE RESULTS\n",
    "\n",
    "It appears our model will predict new data very well. The cross-validation R-squared illustrates that the cv model (on each 4-group out of 5 subsets) explained about 90% of the variation in the new data. This is great news!\n",
    "\n",
    "Note: The cross-validation tells us our model will predict new data very well, but it doesn't actually predict out-of-sample data. We now have the confidence to train the full model and then use it on future data to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
